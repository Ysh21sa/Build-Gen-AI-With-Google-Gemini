{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "dios_wxC1-Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY = \"paste your google api key\""
      ],
      "metadata": {
        "id": "wQ4cEsiP7I6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "## load the Groq and Google API key from the .env file\n",
        "\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "st.title(\"Gemma Model Document Q&A\")\n",
        "\n",
        "llm = ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma-7b-it\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Answer the questions based on the provided context only.\n",
        "    Please provide the most accurate response based on the question\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "    Questions: {input}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def vector_embedding():\n",
        "  if \"vectors\" not in st.session_state:\n",
        "    st.session_state.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    st.session_state.loader = PyPDFDirectoryLoader(\"./us_census\") ## Data Ingestion\n",
        "    st.session_state.docs = st.session_state.loader.load() ## Document Loading\n",
        "    st.session_state.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    st.session_state.final_documents = st.session_state.text_splitter.split_documents(st.session_state.docs)\n",
        "    st.session_state.vectors = FAISS.from_documents(st.session_state.final_documents, st.session_state.embeddings)\n",
        "\n",
        "prompt1 = st.text_input(\"What you want to ask from the documents?\")\n",
        "\n",
        "if st.button(\"Creating vector Store\"):\n",
        "  vector_embedding()\n",
        "  st.write(\"Vector Store Db is ready\")\n",
        "\n",
        "import time\n",
        "\n",
        "if prompt1:\n",
        "  document_chain = create_stuff_documents_chain(llm,prompt)\n",
        "  retriever = st.session_state.vectors.as_retriever()\n",
        "  retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
        "\n",
        "  start = time.process_time()\n",
        "  response = retrieval_chain.invoke({'input':prompt1})\n",
        "  st.write(response['answer'])\n",
        "\n",
        "  # with a streamlit expander\n",
        "  with st.expander(\"Document Similarity Search\"):\n",
        "    # find the relebvant chunks\n",
        "    for i,doc in enumerate(response[\"context\"]):\n",
        "      st.write(doc.page_content)\n",
        "      st.write(\"--------------------------------\")\n"
      ],
      "metadata": {
        "id": "PBLtr-o2mkcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "ESXWIcRFoxym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "gD7qM-n72DiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/qagroq.py &> ./logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "G-Uns4g22FG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}