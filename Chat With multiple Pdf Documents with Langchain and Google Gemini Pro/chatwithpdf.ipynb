{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "TBv4HxoVVoJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GOOGLE_API_KEY = \"paste your google api key\""
      ],
      "metadata": {
        "id": "8vO63sVG_ROs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import google.generativeai as genai\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "def get_pdf_text(pdf_docs):\n",
        "  text=\"\"\n",
        "  for pdf in pdf_docs:\n",
        "    pdf_reader=PdfReader(pdf)\n",
        "    for page in pdf_reader.pages:\n",
        "      text+=page.extract_text()\n",
        "  return text\n",
        "def get_text_chunks(text):\n",
        "  text_splitter=RecursiveCharacterTextSplitter(chunk_size=10000,chunk_overlap=200)\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks\n",
        "\n",
        "def  get_vector_store(text_chunks):\n",
        "  embeddings=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "  vector_store=FAISS.from_texts(embeddings,text_chunks)\n",
        "  vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "def get_conversation_chain():\n",
        "  prompt_template=\"\"\"\n",
        "  Answer the question as detailed as possible from the provided context, make sure to provide all the details,if the answer is not in\n",
        "  provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "  context:\\n {context}?\\n\n",
        "  Question:\\n {question}?\\n\n",
        "\n",
        "  Answer:\n",
        "  \"\"\"\n",
        "\n",
        "  model = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.3)\n",
        "  prompt = PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])\n",
        "  llm=ChatGoogleGenerativeAI(model=\"models/chat-bison-001\")\n",
        "  chain = load_qa_chain(llm,chain_type=\"stuff\",prompt=prompt)\n",
        "  return chain\n",
        "\n",
        "def user_input(user_question):\n",
        "  embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "  new_db = FAISS.load_local(\"faiss_index\",embeddings)\n",
        "\n",
        "  docs = new_db.similarity_search(user_question)\n",
        "\n",
        "  chain = get_conversation_chain()\n",
        "\n",
        "  response = chain(\n",
        "      {\"input_documents\":docs,\"question\":user_question}\n",
        "      , return_only_outputs=True)\n",
        "  print(response)\n",
        "  st.write(\"Reply: \",response[\"output_text\"])\n",
        "\n",
        "def main():\n",
        "  st.set_page_config(\"Chat with Multiple PDF\")\n",
        "  st.header(\"chat with PDF using Gemini\")\n",
        "\n",
        "  user_question = st.text_input(\"answer a question from the pdf\")\n",
        "\n",
        "  if user_question:\n",
        "    user_input(user_question)\n",
        "\n",
        "  with st.sidebar:\n",
        "    st.subheader(\"Menu:\")\n",
        "    pdf_docs = st.file_uploader(\"Upload your pdfs here and click on 'Process'\",accept_multiple_files=True)\n",
        "    if st.button(\"Submit & Process\"):\n",
        "      with st.spinner(\"Processing ...\"):\n",
        "        raw_text = get_pdf_text(pdf_docs)\n",
        "        text_chunks = get_text_chunks(raw_text)\n",
        "        get_vector_store(text_chunks)\n",
        "        st.success(\"done\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "iHv5UjXyjswi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhQ2PaU7E6wV"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "Jo-2DGD8YfuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/chatwithpdf.py &> ./logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "YhUCrrm0YhNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}